include: "Common.snake"
include: "Binning.snake"

import glob
import os
from os.path import dirname,basename,realpath

def bin_paths_by_type(bin_type):
  return [os.path.dirname(path) for path in glob.glob("subgraphs/%s/Bin_*/SCG.fna" % bin_type)]

rule all:
    input: "subgraphs/bin_merged/selected_bins.txt"

rule extract_subgraphs:
    input:   cogs="subgraphs/{bin_type}/{bin}/SCG.fna",
             gfa="assembly/high_res/simplified.gfa"
    output:  touch("subgraphs/{bin_type}/{bin}/raw_subgraphs/subgraph.done")
    log:     "subgraphs/{bin_type}/{bin}/raw_subgraphs/subgraph.log"
    threads: THREADS
    shell:   "{SOFT}/subgraph-extractor -part-seq {input.cogs} -graph {input.gfa} -o $(dirname {output}) -k {ASSEMBLY_K} -t {threads} -cds-len-est {SCG_DATA}/coreCogs.tsv> {log}"

rule create_unitig_profile:
    input: flag="subgraphs/{bin_type}/{bin}/raw_subgraphs/subgraph.done",
           mult_prof="assembly/high_res/simplified.mult_prof"
    output: touch('subgraphs/{bin_type}/{bin}/raw_subgraphs/profile.done')
    shell:  """
            rm -rf $(dirname {input.flag})/*.tsv
            for file in $(dirname {input.flag})/*gfa; do
                stub=${{file%.gfa}}
                awk '/^S/{{print ">"$2"\\n"$3 }}' $file | grep ">" | sed 's/>//g' > $stub.id    
                awk 'FNR==NR {{hash[$1]; next}} $1 in hash' $stub.id {input.mult_prof} > ${{stub}}.tsv
                rm $stub.id
            done
            """

def bin_avg_cov(bin_cov_fn, bin_name):
    with open(bin_cov_fn) as f:
        for l in f:
            #TODO should probably work without strip()
            b, cov = l.strip().split()
            if ("Bin_" + b) == bin_name:
                return cov

    assert False
    return 0
    
#FIXME do I need to specify tmp folder ?
#TODO refactor? (maybe without a loop) ? ? 
rule simplify_subgraphs:
    input: bin_cov="subgraphs/{bin_type}/bin_cov.tsv",
           profiles_flag="subgraphs/{bin_type}/{bin}/raw_subgraphs/profile.done"
    output: touch("subgraphs/{bin_type}/{bin}/simplif/simplif.done")
    threads: THREADS
    run:
      avg_cov = bin_avg_cov(input.bin_cov, wildcards["bin"])
      shell("""
            out=$(dirname {output})/
            rm -rf $out
            mkdir -p $out/tmp
            in=$(dirname {input.profiles_flag})
            for g in $in/*gfa; do
                name=$(basename $g .gfa)
                {SOFT}/spades-gsimplifier $g $out/$name --gfa -k {ASSEMBLY_K} -s $in/$name.stops -d $in/$name.deadends -p $in/$name.tsv -c {avg_cov} -read-length {READ_LENGTH} -t {threads} -tmpdir $out/tmp &> $out/$name.log
            done
            """)



checkpoint identify_bins_to_merge:
    #this is not a good way of defining input : may fail if input is evaluated before execution of some over rule  which should implicitely have been caried out beforehand. The right way to do it, is to have it depend on a checkpoint, for instance it fail if called before bin_merged folder is created.
    input: lambda wildcards:expand("{path}/simplif/simplif.done", path = bin_paths_by_type(wildcards["bin_type"]))
    #TODO should we put cogs to ignore files within the bin subfolders?
    output:  cogs_to_ignore = "subgraphs/{bin_type}/bin_cogs_to_ignore.tsv",
             bins_to_merge = "subgraphs/{bin_type}/bins_to_merge.tsv"
    params:  list_bins = lambda wildcards:" ".join(map(dirname,glob.glob("subgraphs/"+wildcards.bin_type+"/Bin*/"))),
             graph_rel_path = 'simplif/COG*.gfa'
    #TODO use the input somehow? 
    #TODO remove '
    shell:   """
    {SCRIPTS}/Common_unitigs.py -b {params.list_bins} -g {params.graph_rel_path} {MERGE_VALUE} {output.bins_to_merge} {output.cogs_to_ignore} -t {MERGE_THRESHOLD}
    """

checkpoint merge_bins:
    input:  merge_plan = "subgraphs/bin_init/bins_to_merge.tsv",
            contig_assign = "binning/clustering_gt%s_merged.csv" % MIN_CONTIG_SIZE
    output: cluster = "subgraphs/bin_merged/clustering.csv"
    log:    "subgraphs/bin_merged/merge.log"
    shell:  "{SCRIPTS}/merge_bins.py {input.merge_plan} $(dirname {input.merge_plan}) "
            "{input.contig_assign} $(dirname {output.cluster}) &>> {log}"

rule compute_avg_cov_merged:
    input:   "subgraphs/bin_merged/clustering.csv"
    output:  "subgraphs/bin_merged/bin_cov.tsv"
    shell:   "{SCRIPTS}/bin_cov.py {input} {output} {ASSEMBLY_K}"

def read_bad_cogs(filename, bin_):
    with open(filename) as handle:
        return next(line.rstrip().split("\t")[1:] for line in handle if line.rstrip().split("\t")[0]==bin_)

rule flag_bad_cogs:
    input: cogs_to_ignore_file="subgraphs/bin_merged/bin_cogs_to_ignore.tsv",
           simplif_done_file="{path}/{bin}/simplif/simplif.done"
    output: selected="{path}/{bin}/selected_cogs.tsv"
    run:
        all_cogs, = glob_wildcards(os.path.dirname(output[0]) + "/simplif/{cog}.gfa")
        bad_cogs=read_bad_cogs(input.cogs_to_ignore_file,wildcards.bin)
        with open(output["selected"], "w") as out:
            out.write("\n".join(sorted([cog for cog in all_cogs if cog not in bad_cogs])))

def merged_bins_cogs(wildcards):
    checkpoints.merge_bins.get()
    # because we don't have anything to catch the case where extracted subgraph of merged bin need to be merged 
    checkpoints.identify_bins_to_merge.get(bin_type="bin_merged")
    size=os.stat("subgraphs/bin_merged/bins_to_merge.tsv").st_size
    assert size == 0, "subgraphs/bin_merged/bins_to_merge.tsv is not null, it's " % size
    return [realpath(binpath)+"/selected_cogs.tsv" for binpath in bin_paths_by_type("bin_merged")]

rule select_bins_for_strain_analysis:
    input:  select = merged_bins_cogs,
            mags = "binning/list_mags.tsv",
            merge_recipe = "subgraphs/bin_init/bins_to_merge.tsv", 
            input_csv = "subgraphs/bin_merged/clustering.csv"
    output: selected="subgraphs/bin_merged/selected_bins.txt"
    message: "Select bins containing sufficient number of COGs"
    shell: "{SCRIPTS}/this_should_not_be_a_script.py {input.mags} {input.merge_recipe} {output.selected} $(dirname {input.input_csv}) {MIN_ORF_NUMBER_TO_RUN_A_BIN}"
